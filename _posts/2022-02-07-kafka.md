---
title: "Kafka"
excerpt: "카프카, 주키퍼, 프로듀서, 컨슈머, ack"
toc: true
toc_sticky: true
categories:
  - Kafka
last_modified_at: 2022-02-07
---

### Introduction

- 카프카란?

  - 대용량 데이터를 위한, 비동기 처리를 위한 메세지 큐이다.
  - 프로듀서 ↔  브로커 ↔  컨슈머
  - 프로듀서는 카프카(브로커)에게 메세지를 보내고 해당 메세지는 카프카에 저장되어 보관한다.(메모리x 디스크o) 이후 컨슈머는 카프카에 저장되어 있는 메세지를 필요로 할 때 가져갈 수 있다.
  - 카프카, 주키퍼 실행

    ```bash
    # 주키퍼 먼저 시작
    > bin/zookeeper-server-start.sh -daemon config/zookeeper.properties

    # 이후 카프카 시작
    > bin/kafka-server-start.sh -daemon config/server.properties
    ```

- 주키퍼란?
  - 카프카의 노드 관리
  - ~~토픽의 offset 정보 등을 저장~~ → 이전 버전엔 주키퍼였지만 주키퍼 write 오버헤드 때문에 카프카 브로커 내부로 변경
  - 과반수 투표방식의 주체 및 대상이 무엇인진 모르겠지만 무언가를 다수결로 결정하기에 홀수로 구성해야함.
- 토픽이란?

  - 데이터베이스의 테이블 정도의 개념이다. (로우는 메세지)
  - 카프카에 저장되는 데이터(메세지)를 토픽이라는 이름으로 구분짓기 위해 사용한다.
  - 토픽 생성

    ```bash
    # replica-factor, 파티션 각각 1개씩
    > bin/kafka-topics.sh --create \
    	--zookeeper localhost:2181 \
      --bootstrap-server localhost:9092 \
    	--replication-factor 1 \
      --partitions 1 \
      -- topic test-topic

    # Created topic "test"
    ```

  - 토픽 리스트 확인
    ```bash
    > bin/kafka-topics.sh --list \
      --zookeeper localhost:2181
    ```
  - 토픽 세부 정보 확인

    ```bash
    > bin/kafka-topics.sh --describe \
      --bootstrap-server localhost:9092 \
      --topic test-topic

    # Topic:quickstart-events  PartitionCount:1
    # ReplicationFactor:1 Configs:
    # Topic: quickstart-events Partition: 0    Leader: 0   Replicas: 0 Isr: 0
    ```

  - message producing

    ```bash
    > bin/kafka-console-producer.sh \
      --bootstrap-server localhost:9092 \
      --topic test-topic

    > this is test message 1
    > this is test message 2
    ```

  - message consuming

    ```bash
    > bin/kafka-console-consumer.sh \
      --bootstrap-server localhost:9092 \
      --topic test \
      --from-beginning

    # this is test message 1
    # this is test message 2
    ```

- 파티션이란?
  - 토픽을 몇개로 나눌지를 의미한다.
  - 파티션이 2개 이상일 경우 컨슈머에서 메세지 컨슈밍하는 순서는 메세지가 프로듀싱된 순서와 동일하지 않다.
  - 메세지 컨슈밍은 파티션 내부에서만 순서보장이 이루어지기 때문에 a파티션과 b파티션이 있을경우 첫번째 메세지 hi가 a파티션으로, 두번째 메세지 bye가 b파티션으로 들어갔을 때 컨슈머는 어떤 파티션을 먼저 읽을지에 대한 순서보장이 없어서 bye를 먼저 컨슈밍할 수 있다.
- replication-factor란?
  - 카프카 브로커 클러스터링 개수
  - 만약 replication-factor가 3이면 1개의 리더와 2개의 팔로워 브로커로 구성됨
- event streaming platform - kafka 사용 사례 (공식 문서)
  - To process payments and financial transactions in real-time, such as in stock exchanges, banks, and insurances.
  - To track and monitor cars, trucks, fleets, and shipments in real-time, such as in logistics and the automotive industry.
  - To continuously capture and analyze sensor data from IoT devices or other equipment, such as in factories and wind parks.
  - To collect and immediately react to customer interactions and orders, such as in retail, the hotel and travel industry, and mobile applications.
  - To monitor patients in hospital care and predict changes in condition to ensure timely treatment in emergencies.
  - To connect, store, and make available data produced by different divisions of a company.
  - To serve as the foundation for data platforms, event-driven architectures, and microservices.

---

### 컨슈머 그룹

- 컨슈머 그룹이란?
  - 컨슈머 인스턴스들이 속한 그룹
  - 컨슈머 인스턴스란 브로커에서 메세지를 컨슈밍하는 하나의 프로세스 혹은 서버
  - 컨슈머 그룹의 존재 이유
    1. 가용성 : 특정 토픽을 컨슈밍하는 컨슈머 그룹에 여러 컨슈머들이 있어야 하나의 컨슈머가 죽었을 때, 다른 컨슈머들이 작업을 이어갈 수 있다.
    2. offset 관리 : 특정 토픽을 컨슈밍하는 컨슈머들이 만약 그룹화되어있지 않고 따로 논다면 각각의 컨슈머들이 토픽의 파티션에서 어디까지 읽었는지, 다음 데이터는 어느 위치꺼를 읽어야하는지에 대한 offset 관리가 이루어지지 않는다.
- offset이란?
  - 파티션 안에 데이터 위치를 유니크한 숫자로 표시한 것
  - 컨슈머 그룹 단위로 어디까지 데이터를 가져갔는지에 대한 정보를 offset이라고 하며 카프카 브로커 서버에 저장된다.
  - 1번 컨슈머가 1번 파티션의 4번 메세지까지 읽었다. → (x)
  - 컨슈머 그룹 A가 1번 파티션의 4번 메세지까지 읽었다. → (o)
- 컨슈머 그룹과 파티션 수의 관계
  - 하나의 파티션에 대해 컨슈머 그룹 내부 하나의 컨슈머만이 접근할 수 있다. 그래야 파티션 내에서 데이터가 읽어지는 순서가 보장되므로
  - 파티션 수 < 컨슈머 인스턴스 수 → 노는 컨슈머가 생겨서 비효율
  - 파티션 수 > 컨슈머 인스턴스 수 → 하나의 컨슈머가 2개 이상의 파티션을 읽게 되어 속도 저하
  - 파티션 수 == 컨슈머 인스턴스 수 → 이게 가장 이상적
  - 만약 이런데도 병목현상이 일어난다면 파티션 수와 컨슈머의 수를 동일하게 늘리는 스케일 아웃을 고려해야한다. 단 파티션은 한 번 생성되면 삭제할 수 없으니 잘 고려해야 한다.
- 다중 컨슈머 그룹
  - 2개의 컨슈머 그룹의 각각의 컨슈머가 동일한 하나의 토픽 파티션을 읽을 수도 있긴하다.
  - 예를 들어 광고 관련 플랫폼에서 사용자의 클릭 정보가 토픽이고 해당 토픽을 사용하는 컨슈머가 리포트 어플리케이션, 과금 어플리케이션 2가지라면 각각의 컨슈머그룹에서 동일한 클릭정보를 가져가야하기 때문이다.
  - offset이란 컨슈머 그룹 ↔  토픽 파티션 사이의 정보이므로, 당연히 각 컨슈머 그룹마다 다른 offset정보가 각각 저장 관리되며 서로 영향을 미치지 않는다.
- 리밸런싱
  - 기존 컨슈머 구성으론 병목현상이 발생하여 하나의 컨슈머를 추가할 때 기존에 있던 컨슈머와 파티션의 소유권을 나눠 갖는 작업을 수행하는데 이 과정을 리밸런싱이라고 한다. (병목현상에서의 리밸런싱)
  - 만약 2개의 컨슈머로 4개의 파티션을 읽고 있는데 어떤 하나의 컨슈머가 장애 상황으로 인해 죽는다면 2개의 파티션의 메세지들은 읽혀지지않고 남게 되는데, 이상황을 해결하기 위해 살아남은 나머지 하나의 컨슈머에게 읽히지 않는 2개의 파티션을 재할당하는 것이 리밸런싱이다. (장애상황에서의 리밸런싱)
  - 컨슈머 그룹은 그룹 코디네이터라고 하는 카프카 브로커 서버를 하나 할당받는데, 여기에다가 각 컨슈머들이 자신이 살아있음을 알리는 heart beat을 보낸다. 그룹 코디네이터는 이런 heart beat 정보를 컨슈머 그룹 리더에게 전달하고 이 리더가 파티션 소유권을 분배 작업을 수행한다.
  - 소유권 분배 결과를 다시 그룹 코디네이터에게 알려주고 그룹 코디네이터가 각각의 컨슈머들에게 파티션 소유권 분배정보를 전달한다. (컨슈머 그룹끼리의 소통x) (리더 컨슈머는 그냥 제일 먼저 등록된 컨슈머임)

---

### Ack

- tcp handshake에서 두번째로 서버가 클라이언트에게 보내는 ack패킷과 비슷한 것 같다.
- 프로듀서가 카프카 브로커에게 메세지를 보냈는데 이를 잘 받았는지 확인 여부를 결정하는 옵션이다. (프로듀서의 옵션이다.)

1. ack == 0 → 잘 받았는지 확인하지 않는다.
   - 프로듀서 입장에선 메세지를 보냈는데 브로커가 죽은 상태라면 해당 메세지는 손실된다.
2. ack == 1 → 리더 브로커에게만 잘 받았는지 확인한다. (팔로워들은 확인x)
   - 리더가 확인응답을 보내고 팔로워에게 복제가 되기 전 리더가 죽게 되면 해당 메세지는 손실될 수 있다. (리더 브로커에 메세지가 들어오면 다른 팔로워 브로커들이 해당 메세지를 다 복제하나보다.)
3. ack == all (-1) → 리더와 팔로워 모두 잘 받았는지 확인한다.
   - 메세지가 손실될 확률은 거의 없다.

- 프로듀서가 브로커로부터 잘 받았는지에 대한 확인응답을 받는 데까지 기다리는 시간은 프로듀서가 하염없이 기다리므로 속도 면에서 영향이 있다.

---

### 참조 사이트

[https://kafka.apache.org/documentation](https://kafka.apache.org/documentation/#quickstart)

[https://soft.plusblog.co.kr/29](https://soft.plusblog.co.kr/29)

[https://www.popit.kr/kafka-운영자가-말하는-producer-acks/](https://www.popit.kr/kafka-%ec%9a%b4%ec%98%81%ec%9e%90%ea%b0%80-%eb%a7%90%ed%95%98%eb%8a%94-producer-acks/)
